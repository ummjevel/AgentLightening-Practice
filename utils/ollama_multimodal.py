"""Ollama multimodal integration for PDF analysis."""

import logging
import base64
from typing import List, Dict, Any
from pathlib import Path
import fitz  # PyMuPDF
from PIL import Image
import io
import requests


logger = logging.getLogger(__name__)


class OllamaMultimodal:
    """Ollama multimodal model integration for analyzing PDFs with images."""

    def __init__(self, config: Dict[str, Any]):
        """
        Initialize OllamaMultimodal.

        Args:
            config: Configuration dictionary
        """
        self.config = config

        # Get Ollama config
        ollama_config = config.get('ollama', {})
        self.enabled = ollama_config.get('enabled', False)
        self.base_url = ollama_config.get('base_url', 'http://localhost:11434')
        self.model = ollama_config.get('model', 'llava')
        self.temperature = ollama_config.get('temperature', 0.7)
        self.num_ctx = ollama_config.get('num_ctx', 4096)

        # PDF to image settings
        pdf_img_config = ollama_config.get('pdf_to_image', {})
        self.dpi = pdf_img_config.get('dpi', 150)
        self.max_pages = pdf_img_config.get('max_pages', 10)
        self.img_format = pdf_img_config.get('format', 'png')

        # Get summary config
        summary_config = config.get('summary', {})
        self.language = summary_config.get('language', 'ko')

        logger.info(f"Initialized OllamaMultimodal (enabled: {self.enabled}, model: {self.model})")

    def pdf_to_images(self, pdf_path: str) -> List[str]:
        """
        Convert PDF pages to base64 encoded images.

        Args:
            pdf_path: Path to PDF file

        Returns:
            List of base64 encoded image strings
        """
        logger.info(f"Converting PDF to images: {pdf_path}")

        images = []

        try:
            doc = fitz.open(pdf_path)
            num_pages = min(len(doc), self.max_pages)

            for page_num in range(num_pages):
                page = doc[page_num]

                # Render page to image
                mat = fitz.Matrix(self.dpi / 72, self.dpi / 72)  # 72 is default DPI
                pix = page.get_pixmap(matrix=mat)

                # Convert to PIL Image
                img_data = pix.tobytes("png")
                img = Image.open(io.BytesIO(img_data))

                # Convert to base64
                buffered = io.BytesIO()
                img.save(buffered, format=self.img_format.upper())
                img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')

                images.append(img_base64)

                logger.debug(f"Converted page {page_num + 1}/{num_pages}")

            doc.close()

            logger.info(f"Converted {len(images)} pages to images")

            return images

        except Exception as e:
            logger.error(f"Error converting PDF to images: {e}")
            return []

    def analyze_paper_multimodal(self, paper_data: Dict[str, Any]) -> str:
        """
        Analyze paper using multimodal model with PDF images.

        Args:
            paper_data: Paper data dictionary

        Returns:
            Generated summary text
        """
        if not self.enabled:
            raise RuntimeError("Ollama multimodal is not enabled in config")

        metadata = paper_data['metadata']
        title = metadata['title']
        authors = ', '.join(metadata['authors'][:3])
        abstract = metadata['summary']
        pdf_path = paper_data.get('pdf_path', '')

        logger.info(f"Analyzing paper with multimodal model: {title[:50]}...")

        # Convert PDF to images
        page_images = self.pdf_to_images(pdf_path)

        if not page_images:
            logger.warning("No images extracted, falling back to abstract only")
            # Fallback to abstract-only analysis
            return self._analyze_abstract_only(title, authors, abstract)

        # Create multimodal prompt
        if self.language == 'ko':
            prompt = f"""ë‹¤ìŒ ë…¼ë¬¸ì„ ë¶„ì„í•˜ê³  êµ¬ì¡°í™”ëœ ìš”ì•½ì„ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

ë…¼ë¬¸ ì œëª©: {title}
ì €ì: {authors}
ì´ˆë¡: {abstract}

PDF ì´ë¯¸ì§€ë¥¼ ë³´ê³  ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. ğŸ“‹ í•œëˆˆì— ë³´ê¸° (2-3ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ ë‚´ìš© ìš”ì•½)

2. ğŸ¯ ì—°êµ¬ ëª©ì  (ì´ ì—°êµ¬ê°€ í•´ê²°í•˜ê³ ì í•˜ëŠ” ë¬¸ì œ)

3. ğŸ”¬ ë°©ë²•ë¡  (ì‚¬ìš©ëœ í•µì‹¬ ê¸°ìˆ ì´ë‚˜ ì ‘ê·¼ ë°©ë²•, ê·¸ë¦¼ê³¼ ìˆ˜ì‹ ì°¸ê³ )

4. ğŸ“Š ì£¼ìš” ê²°ê³¼ (í•µì‹¬ ë°œê²¬ì´ë‚˜ ì„±ëŠ¥ ê°œì„ , ê·¸ë˜í”„ë‚˜ í‘œ ì°¸ê³ )

5. ğŸ’¡ ì˜ì˜ ë° ì˜í–¥ (ì´ ì—°êµ¬ì˜ í•™ë¬¸ì /ì‹¤ìš©ì  ê°€ì¹˜)

6. ğŸ–¼ï¸ ì£¼ìš” ê·¸ë¦¼ ì„¤ëª… (ë…¼ë¬¸ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ê·¸ë¦¼ë“¤ì— ëŒ€í•œ ì„¤ëª…)

ê° ì„¹ì…˜ì„ ëª…í™•í•˜ê²Œ êµ¬ë¶„í•˜ê³ , PDF ì´ë¯¸ì§€ì— ë‚˜ì˜¨ ìˆ˜ì‹, ê·¸ë˜í”„, ë‹¤ì´ì–´ê·¸ë¨ì„ ì°¸ê³ í•˜ì—¬ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”."""
        else:
            prompt = f"""Please analyze the following paper and create a structured summary.

Paper Title: {title}
Authors: {authors}
Abstract: {abstract}

Analyze the PDF images and provide:

1. ğŸ“‹ Key Highlights (2-3 sentence core summary)

2. ğŸ¯ Research Objective (Problem this research aims to solve)

3. ğŸ”¬ Methodology (Core techniques or approaches, reference figures and equations)

4. ğŸ“Š Main Results (Key findings or performance improvements, reference graphs/tables)

5. ğŸ’¡ Significance & Impact (Academic/practical value)

6. ğŸ–¼ï¸ Key Figures Description (Explain the most important figures in the paper)

Provide detailed explanations referencing equations, graphs, and diagrams from the PDF images."""

        try:
            # Call Ollama API with multimodal input
            summary = self._call_ollama_multimodal(prompt, page_images)

            logger.info(f"Successfully analyzed paper with multimodal model")

            return summary

        except Exception as e:
            logger.error(f"Error in multimodal analysis: {e}")
            # Fallback to abstract only
            return self._analyze_abstract_only(title, authors, abstract)

    def _call_ollama_multimodal(self, prompt: str, images: List[str]) -> str:
        """
        Call Ollama API with multimodal input.

        Args:
            prompt: Text prompt
            images: List of base64 encoded images

        Returns:
            Generated text response
        """
        url = f"{self.base_url}/api/generate"

        # Prepare request payload
        payload = {
            "model": self.model,
            "prompt": prompt,
            "images": images,
            "stream": False,
            "options": {
                "temperature": self.temperature,
                "num_ctx": self.num_ctx
            }
        }

        logger.debug(f"Calling Ollama API: {url}")

        response = requests.post(url, json=payload, timeout=300)  # 5 min timeout

        if response.status_code != 200:
            raise RuntimeError(f"Ollama API error: {response.status_code} - {response.text}")

        result = response.json()
        return result.get('response', '')

    def _analyze_abstract_only(self, title: str, authors: str, abstract: str) -> str:
        """
        Fallback method to analyze only abstract without images.

        Args:
            title: Paper title
            authors: Paper authors
            abstract: Paper abstract

        Returns:
            Generated summary
        """
        logger.warning("Using abstract-only fallback")

        if self.language == 'ko':
            return f"""ğŸ“‹ í•œëˆˆì— ë³´ê¸°
ì´ ë…¼ë¬¸ì€ ì œí•œëœ ì •ë³´ë¡œ ì¸í•´ ìƒì„¸ ë¶„ì„ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.

ë…¼ë¬¸ ì œëª©: {title}
ì €ì: {authors}

ì´ˆë¡ ìš”ì•½:
{abstract[:500]}...

âš ï¸ ì°¸ê³ : PDF ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨ë¡œ ì´ˆë¡ë§Œ í‘œì‹œë©ë‹ˆë‹¤."""
        else:
            return f"""ğŸ“‹ Key Highlights
Detailed analysis unavailable due to limited information.

Paper Title: {title}
Authors: {authors}

Abstract Summary:
{abstract[:500]}...

âš ï¸ Note: Showing abstract only due to PDF image analysis failure."""
